{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install onnx\n",
    "# ! pip install onnxruntime\n",
    "# ! python3 -m pip install --upgrade pip\n",
    "# ! pip uninstall onnxruntime-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "from torchvision.models import mobilenetv2\n",
    "from pathlib import Path\n",
    "from onnxruntime.tools.convert_onnx_models_to_ort import convert_onnx_models_to_ort, OptimizationStyle\n",
    "import onnxruntime as ort\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 224, 224, requires_grad=True)\n",
    "model = mobilenetv2.mobilenet_v2(pretrained=True)\n",
    "torch.onnx.export(model, x, \"temp/mobilenet_v2.onnx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 14:35:20,520 ort_format_model.utils [INFO] - Created config in /Users/takenoko/Develop/onnx-ort/temp/mobilenet_v2.required_operators.config\n",
      "2023-12-20 14:35:20,641 ort_format_model.utils [INFO] - Created config in /Users/takenoko/Develop/onnx-ort/temp/mobilenet_v2.required_operators.with_runtime_opt.config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting models with optimization style 'Fixed' and level 'all'\n",
      "Converting optimized ONNX model /Users/takenoko/Develop/onnx-ort/temp/mobilenet_v2.onnx to ORT format model /Users/takenoko/Develop/onnx-ort/temp/mobilenet_v2.ort\n",
      "Converted 1/1 models successfully.\n",
      "Generating config file from ORT format models with optimization style 'Fixed' and level 'all'\n",
      "Converting models with optimization style 'Runtime' and level 'all'\n",
      "Converting optimized ONNX model /Users/takenoko/Develop/onnx-ort/temp/mobilenet_v2.onnx to ORT format model /Users/takenoko/Develop/onnx-ort/temp/mobilenet_v2.with_runtime_opt.ort\n",
      "Converted 1/1 models successfully.\n",
      "Converting models again without runtime optimizations to generate a complete config file. These converted models are temporary and will be deleted.\n",
      "Converting optimized ONNX model /Users/takenoko/Develop/onnx-ort/temp/mobilenet_v2.onnx to ORT format model /Users/takenoko/Develop/onnx-ort/temp/tmpx109gy0m.without_runtime_opt/mobilenet_v2.ort\n",
      "Converted 1/1 models successfully.\n",
      "Generating config file from ORT format models with optimization style 'Runtime' and level 'all'\n"
     ]
    }
   ],
   "source": [
    "convert_onnx_models_to_ort(\n",
    "    model_path_or_dir = Path(\"temp/mobilenet_v2.onnx\"),\n",
    "    optimization_styles = [OptimizationStyle.Fixed, OptimizationStyle.Runtime]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"temp/mobilenet_v2.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input.1']: [[1, 3, 224, 224]]\n",
      "['536']: [[1, 1000]]\n",
      "(1, 1, 1000)\n"
     ]
    }
   ],
   "source": [
    "x = np.ones((1, 3, 224, 224), dtype=np.float32)\n",
    "ort_sess = ort.InferenceSession('temp/mobilenet_v2.onnx')\n",
    "\n",
    "input_names = [x.name for x in ort_sess.get_inputs()]\n",
    "input_shapes = [x.shape for x in ort_sess.get_inputs()]\n",
    "output_names = [x.name for x in ort_sess.get_outputs()]\n",
    "output_shapes = [x.shape for x in ort_sess.get_outputs()]\n",
    "print(f\"{input_names}: {input_shapes}\")\n",
    "print(f\"{output_names}: {output_shapes}\")\n",
    "\n",
    "outputs = ort_sess.run(None, {input_names[0]: x})\n",
    "print(np.array(outputs).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}